name: Update Index

on:
  push:
    branches: ["**"]
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: update-index-${{ github.ref }}
  cancel-in-progress: true

jobs:
  update-index:
    runs-on: ubuntu-latest
    env:
      README_PATH: README.md
      INDEX_HEADING: "### 📑 Project Index"
      AI_MODEL: gpt-4o-mini
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

    steps:
      - uses: actions/checkout@v4
        with:
          persist-credentials: false
          fetch-depth: 0
          ref: ${{ github.ref }}

      - uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Write indexer script to file
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p .github/tmp
          cat > .github/tmp/update-index.mjs <<'NODE'
          import fs from 'fs';
          import path from 'path';
          import { setTimeout as delay } from 'timers/promises';

          const README_PATH = process.env.README_PATH || 'README.md';
          const INDEX_HEADING = process.env.INDEX_HEADING || '### 📑 Project Index';
          const OPENAI_API_KEY = process.env.OPENAI_API_KEY || '';
          const AI_MODEL = process.env.AI_MODEL || 'gpt-4o-mini';

          if (!fs.existsSync(README_PATH)) {
            console.error(`❌ README not found at ${README_PATH}`);
            process.exit(1);
          }

          // ---------- SETTINGS ----------
          const IGNORE = new Set([
            '.git','node_modules','.DS_Store','.idea','.vscode','.env','.venv',
            '.next','dist','build','coverage','.turbo','.cache'
          ]);

          const MAX_SAMPLE_BYTES = 65536; // 64KB per file for better summaries
          const AI_TIMEOUT_MS = 45000;

          // ---------- HELPERS ----------
          function listDir(abs) {
            return fs.readdirSync(abs, { withFileTypes: true })
              .filter(e => !IGNORE.has(e.name))
              .sort((a, b) => {
                if (a.isDirectory() !== b.isDirectory()) return a.isDirectory() ? -1 : 1;
                return a.name.localeCompare(b.name);
              });
          }

          function safeRead(fileAbs, maxBytes = MAX_SAMPLE_BYTES) {
            try {
              const b = fs.readFileSync(fileAbs);
              const head = b.subarray(0, Math.min(2048, b.length));
              let nonText = 0;
              for (let i = 0; i < head.length; i++) {
                const byte = head[i];
                if (byte === 0) { nonText = 9999; break; }
                if (byte < 9 || (byte > 13 && byte < 32)) nonText++;
              }
              const isBinary = nonText > 32;
              if (isBinary) return { text: '(binary or non-text content omitted)', isBinary: true, size: b.length };
              return { text: b.toString('utf8', 0, Math.min(b.length, maxBytes)), isBinary: false, size: b.length };
            } catch {
              return { text: '', isBinary: false, size: 0 };
            }
          }

          function quickSignals(sample, rel) {
            const out = {};
            out.functions = Array.from(sample.matchAll(/\bfunction\s+([A-Za-z0-9_]+)/g)).map(m=>m[1]);
            out.exports = Array.from(sample.matchAll(/\bexport\s+(?:default\s+)?(?:function|class|const|let|var)?\s*([A-Za-z0-9_]+)/g)).map(m=>m[1]);
            out.imports = Array.from(sample.matchAll(/\bfrom\s+['"]([^'"]+)['"]/g)).map(m=>m[1]).slice(0,6);
            out.routes = Array.from(sample.matchAll(/\b(app|router)\.(get|post|put|delete|patch)\(['"`]([^'"`]+)['"`]\)/g)).map(m=>`${m[2].toUpperCase()} ${m[3]}`);
            out.react = /from\s+['"]react['"]/.test(sample) || /tsx?$/i.test(rel);
            out.next = /from\s+['"]next(\/.*)?['"]/.test(sample) || /(?:^|\/)(app|pages)\//.test(rel);
            out.tailwind = /class(Name)?=/.test(sample) && /(bg-|text-|flex|grid|rounded|shadow)/.test(sample);
            return out;
          }

          function fallbackDescribe(rel, sample = '') {
            const n = rel.toLowerCase();
            if (n.endsWith('/readme.md') || n === 'readme.md') return 'Project documentation with overview, setup and usage.';
            if (n.endsWith('package.json')) return 'Node package manifest defining scripts, dependencies and project metadata.';
            if (/pnpm-lock\.yaml$|yarn\.lock$|package-lock\.json$/.test(n)) return 'Dependency lockfile pinning exact versions for reproducible installs.';
            if (/\.(png|jpg|jpeg|gif|svg|ico|webp|ttf|otf|woff2?)$/i.test(n)) return 'Static asset (image or font).';
            if (/\.(css|scss|sass)$/i.test(n)) return 'Stylesheet defining layout and utility classes.';
            if (/\.html$/i.test(n)) return 'Static HTML markup for a page or template.';
            if (/\.(ts|tsx|js|jsx)$/i.test(n)) {
              const sig = quickSignals(sample, rel);
              const bits = [];
              if (sig.next) bits.push('Next.js module');
              else if (sig.react) bits.push('React component/module');
              else bits.push('JavaScript/TypeScript module');
              if (sig.routes?.length) bits.push(`routes: ${sig.routes.slice(0,3).join(', ')}${sig.routes.length>3?'…':''}`);
              if (sig.exports?.length) bits.push(`exports: ${sig.exports.slice(0,4).join(', ')}${sig.exports.length>4?'…':''}`);
              if (sig.functions?.length && !sig.exports.length) bits.push(`functions: ${sig.functions.slice(0,4).join(', ')}${sig.functions.length>4?'…':''}`);
              if (sig.tailwind) bits.push('uses Tailwind utilities');
              if (sig.imports?.length) bits.push(`imports ${sig.imports.slice(0,3).join(', ')}${sig.imports.length>3?'…':''}`);
              return bits.join('; ') + '.';
            }
            if (/\.(md|mdx)$/i.test(n)) return 'Markdown content for documentation or pages.';
            if (/\.(json)$/i.test(n)) return 'JSON data or configuration.';
            if (/\.(yml|yaml)$/i.test(n)) return 'YAML configuration (CI/tooling).';
            return 'Repository file.';
          }

          async function aiDescribeFile(relPath, sample) {
            if (!OPENAI_API_KEY) return fallbackDescribe(relPath, sample);

            const controller = new AbortController();
            const timer = setTimeout(() => controller.abort(), AI_TIMEOUT_MS);

            // Keep prompt labels simple (avoid YAML-like "key: value" to prevent linter confusion)
            const sys = "You are a precise repository indexer. Produce a compact, rich summary for ONE file. Write 3–5 crisp sentences (60–140 words). Explain WHAT the file is for, HOW it works, and WHAT code it contains. Mention main exports/functions/classes, routes/components, config keys, or frameworks. If binary/empty, say so and infer role if possible. No markdown headers, no filename repetition, no disclaimers. Output must be a SINGLE LINE (replace newlines with spaces). End with a period.";
            const usr =
              "PATH >> " + relPath + "\n" +
              "CONTEXT >> personal portfolio, likely Next.js/React/Tailwind.\n" +
              "SAMPLE(" + (sample?.length || 0) + ") >>\n" +
              (sample || '(empty/binary)') + "\n" +
              "RETURN >> one single-line summary (3–5 sentences).";

            try {
              const res = await fetch('https://api.openai.com/v1/chat/completions', {
                method: 'POST',
                headers: {
                  'Authorization': `Bearer ${OPENAI_API_KEY}`,
                  'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                  model: AI_MODEL,
                  messages: [
                    { role: 'system', content: sys },
                    { role: 'user', content: usr }
                  ],
                  temperature: 0.15,
                  max_tokens: 240
                }),
                signal: controller.signal
              });

              clearTimeout(timer);

              if (!res.ok) {
                const errTxt = await res.text().catch(()=>String(res.status));
                console.warn(`⚠️ AI describe failed (${res.status}): ${errTxt}`);
                return fallbackDescribe(relPath, sample);
              }
              const data = await res.json();
              const text = data?.choices?.[0]?.message?.content ?? '';
              if (!text.trim()) return fallbackDescribe(relPath, sample);

              let line = text.replace(/\s+/g, ' ').trim();
              if (line.length > 600) line = line.slice(0, 600).trimEnd() + '…';
              if (!/[.!?]$/.test(line)) line += '.';
              return line;
            } catch (e) {
              console.warn(`⚠️ AI describe error: ${e?.message || e}`);
              return fallbackDescribe(relPath, sample);
            }
          }

          async function buildDetailsForDir(rootAbs, relDir) {
            const abs = path.join(rootAbs, relDir);
            const entries = listDir(abs);
            const files = entries.filter(e => e.isFile());
            const dirs  = entries.filter(e => e.isDirectory());

            let html = '';
            if (files.length) {
              html += '      <ul>\n';
              for (const f of files) {
                const relPath = path.posix.join(relDir, f.name).replace(/\\/g, '/');
                const { text: sample } = safeRead(path.join(abs, f.name));
                const desc = await aiDescribeFile(relPath, sample);
                const href = path.posix.join('.', relPath);
                html += `         <li><b><a href="${href}">${f.name}</a></b> — ${desc}</li>\n`;
              }
              html += '      </ul>\n';
            }

            for (const d of dirs) {
              const childRel = path.posix.join(relDir, d.name).replace(/\\/g, '/');
              html += '      <details>\n';
              html += `         <summary><b>${d.name}</b></summary>\n`;
              html += await buildDetailsForDir(rootAbs, childRel);
              html += '      </details>\n';
            }

            return html;
          }

          async function buildProjectIndex() {
            const repoName = (process.env.GITHUB_REPOSITORY || '').split('/').pop()
              || path.basename(process.cwd());
            const repoNameUpper = repoName.toUpperCase();

            let out = '';
            out += `${INDEX_HEADING}\n\n`;
            out += '<details open>\n';
            out += `   <summary><b>${repoNameUpper}/</b></summary>\n`;

            const rootEntries = listDir(process.cwd());
            const rootFiles = rootEntries.filter(e => e.isFile());
            if (rootFiles.length) {
              out += '   <details>\n';
              out += '      <summary><b>__root__</b></summary>\n';
              out += '      <ul>\n';
              for (const f of rootFiles) {
                const { text: sample } = safeRead(path.join(process.cwd(), f.name));
                const desc = await aiDescribeFile(f.name, sample);
                const href = `./${f.name}`;
                const htmlLine = `         <li><b><a href="${href}">${f.name}</a></b> — ${desc}</li>\n`;
                out += htmlLine;
              }
              out += '      </ul>\n';
              out += '   </details>\n';
            }

            for (const d of rootEntries.filter(e => e.isDirectory())) {
              const rel = d.name;
              out += '   <details>\n';
              out += `      <summary><b>${d.name}</b></summary>\n`;
              out += await buildDetailsForDir(process.cwd(), rel);
              out += '   </details>\n\n';
            }

            out += '\n</details>';
            return out;
          }

          function replaceRangeByHR(readme, newSection) {
            const startIdx = readme.indexOf(INDEX_HEADING);
            if (startIdx === -1) {
              const sep = readme.endsWith('\n') ? '' : '\n';
              return readme + sep + '\n---\n' + newSection + '\n';
            }
            const afterStart = startIdx + INDEX_HEADING.length;
            const after = readme.slice(afterStart);
            const HR_RX = /(?:^|\n)\s*---\s*(?:\n|$)/m;
            const hrMatch = after.match(HR_RX);
            const endIdx = hrMatch ? (afterStart + hrMatch.index) : readme.length;
            const before = readme.slice(0, startIdx);
            const tail = readme.slice(endIdx);
            return before + newSection + tail;
          }

          (async () => {
            const readme = fs.readFileSync(README_PATH, 'utf8');
            const newSection = await buildProjectIndex();
            const updated = replaceRangeByHR(readme, newSection);

            if (updated === readme) {
              console.log('No changes to Project Index.');
              process.exit(0);
            }

            fs.writeFileSync(README_PATH, updated, 'utf8');
            console.log('✅ Project Index updated in README (rich AI summaries).');
          })().catch(e => { console.error('❌ Failed:', e); process.exit(1); });
          NODE

      - name: Run indexer
        shell: bash
        run: |
          set -euo pipefail
          node .github/tmp/update-index.mjs

      - name: Commit, rebase on remote, and push
        env:
          PAT_OR_TOKEN: ${{ secrets.PERSONAL_TOKEN || secrets.GITHUB_TOKEN }}
          README_PATH: README.md
        shell: bash
        run: |
          set -euo pipefail

          BRANCH="${GITHUB_REF_NAME:-$(git rev-parse --abbrev-ref HEAD)}"

          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          git remote set-url origin "https://x-access-token:${PAT_OR_TOKEN}@github.com/${GITHUB_REPOSITORY}.git"

          if git diff --quiet -- "${README_PATH}"; then
            echo "No changes."
            exit 0
          fi

          git add "${README_PATH}"
          git commit -m "docs: auto-update 📑 Project Index with rich AI summaries" || true

          git fetch origin "${BRANCH}"
          git pull --rebase --autostash origin "${BRANCH}" || true

          git add "${README_PATH}" || true
          git diff --cached --quiet || git commit --no-edit || true

          if ! git push origin "HEAD:${BRANCH}"; then
            echo "Push rejected, syncing once and retrying…"
            git fetch origin "${BRANCH}"
            git pull --rebase --autostash origin "${BRANCH}" || true
            git add "${README_PATH}" || true
            git diff --cached --quiet || git commit --no-edit || true
            git push origin "HEAD:${BRANCH}"
          fi
